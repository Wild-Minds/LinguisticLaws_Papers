#Zipf's law analysis----
#Correlation anaylsis between f and d
GestureTypes <- read.csv(file.choose(), header = T) #Load data
cor.test(GestureTypes$F, GestureTypes$d, method = 'spearman', alternative='greater') #correlation between f and d
cor.test(GestureTypes$F, GestureTypes$D, method = 'spearman') #Control correlation between D and f


#Excluding the outlier object shake
FreqeuncySort<-GestureTypes[order(-GestureTypes$F),]
GestureTypesNoOS <-FreqeuncySort[2:26,]

cor.test(GestureTypesNoOS$F, GestureTypesNoOS$d, method = 'spearman', alternative ='greater') #correlation between f and d
cor.test(GestureTypesNoOS$F, GestureTypesNoOS$D, method = 'spearman') #Control correlation between D and f


#Is L significnatly small for gesture types? from Heesen et al. (2019)
reps <- 100000
results <- rep(0, reps)
x <- c(GestureTypes$p)
y <- c(GestureTypes$d)
L <- sum(x*y)
print (c("real L is", L))
sortvector <- 1:length(x)
for (i in 1:reps)
{
  sortvector <- sample(sortvector, replace = F)
  xtemp <- x[sortvector]
  L_temp <- sum(xtemp *y)
  results[i] <- L_temp
}
hist(results)
is_small <- sum(results <L) #changed check if it is significiantly big swap '<' with '>'
print(c("P of being so small is estimated as ", is_small/reps)) 

#Is L significnatly small when excluding the outlier?
reps <- 100000
results <- rep(0, reps)
x <- c(GestureTypesNoOS$p)
y <- c(GestureTypesNoOS$d)
L <- sum(x*y)
print (c("real L is", L))
sortvector <- 1:length(x)
for (i in 1:reps)
{
  sortvector <- sample(sortvector, replace = F)
  xtemp <- x[sortvector]
  L_temp <- sum(xtemp *y)
  results[i] <- L_temp
}
hist(results)
is_small <- sum(results <L) #changed check if it is significiantly big swap '<' with '>'
print(c("P of being so small is estimated as ", is_small/reps)) 

head(GestureTypes)
#subset analysis manual vs whole body
ManualBody <-GestureTypes[order(GestureTypes$Category),]

Body <- ManualBody[1:5,]

cor.test(Body$F, Body$d, method = 'spearman', alternative='greater') #correlation between f and d
cor.test(Body$F, Body$d, method = 'spearman') #Control correlation between D and f

Manual <- ManualBody[6:26,]
cor.test(Manual$F, Manual$d, method = 'spearman', alternative = 'greater') #correlation between f and d
cor.test(Manual$F, Manual$d, method = 'spearman') #Control correlation between D and f


#Is L significantly small for manual gestures?
reps <- 100000
results <- rep(0, reps)
x <- c(Manual$p)
y <- c(Manual$d)
L <- sum(x*y)
print (c("real L is", L))
sortvector <- 1:length(x)
for (i in 1:reps)
{
  sortvector <- sample(sortvector, replace = F)
  xtemp <- x[sortvector]
  L_temp <- sum(xtemp *y)
  results[i] <- L_temp
}
hist(results)
is_small <- sum(results <L) #check if it is significiantly big swap '<' with '>'
print(c("P of being so small is estimated as ", is_small/reps)) 

#Is L significantly small for body gestures?
reps <- 100000
results <- rep(0, reps)
x <- c(Body$p)
y <- c(Body$d)
L <- sum(x*y)
print (c("real L is", L))
sortvector <- 1:length(x)
for (i in 1:reps)
{
  sortvector <- sample(sortvector, replace = F)
  xtemp <- x[sortvector]
  L_temp <- sum(xtemp *y)
  results[i] <- L_temp
}
hist(results)
is_small <- sum(results <L) #check if it is significiantly big swap '<' with '>'
print(c("P of being so small is estimated as ", is_small/reps)) 


#Menzerath's law analysis ----
GestureTokens<- read.csv(file.choose(), header=T)
cor.test(GestureTokens$Size, GestureTokens$d, method = 'spearman') #Correlation between sequence size and mean gesture duration per each sequence
cor.test(GestureTokens$Size, GestureTokens$D, method = 'spearman', alternative='greater') #Control correlation between T and n


#is M significanlty small?
reps <- 100000
results <- rep(0, reps)
x <- c(GTMixed$Size)
y <- c(GTMixed$d)
M <- sum(x*y)
print (c("real M is", M))
sortvector <- 1:length(x)
for (i in 1:reps)
{
  sortvector <- sample(sortvector, replace = F)
  xtemp <- x[sortvector]
  M_temp <- sum(xtemp *y)
  results[i] <- M_temp
}
hist(results)
is_small <- sum(results 
                >M)
print(c("P of being so small is estimated as ", is_small/reps))

#Subset Menzerath's law analysis 
#Manual sequences
GTManual <-subset(GestureTokens, Type=='manual')
head(GTManual)
cor.test(GTManual$Size, GTManual$d, method = 'spearman', alternative='greater') #Correlation between t and n per each sequence
cor.test(GTManual$Size, GTManual$D, method = 'spearman') #Control correlation between T and n

#Is M significanlty small for manual seqeuences?
reps <- 100000
results <- rep(0, reps)
x <- c(GTManual$Size)
y <- c(GTManual$d)
M <- sum(x*y)
print (c("real M is", M))
sortvector <- 1:length(x)
for (i in 1:reps)
{
  sortvector <- sample(sortvector, replace = F)
  xtemp <- x[sortvector]
  M_temp <- sum(xtemp *y)
  results[i] <- M_temp
}
hist(results)
is_small <- sum(results 
                >M)
print(c("P of being so small is estimated as ", is_small/reps))


#Mixed sequences
GTMixed <-subset(GestureTokens, Type=='Mixed')
cor.test(GTMixed$Size, GTMixed$d, method = 'spearman', alternative = 'greater')#Correlation between t and n per each sequence
cor.test(GTMixed$Size, GTMixed$D, method = 'spearman')  #Control correlation between T and n

#Is M significantly small for mixed sequences?
reps <- 100000
results <- rep(0, reps)
x <- c(GTMixed$Size)
y <- c(GTMixed$d)
M <- sum(x*y)
print (c("real M is", M))
sortvector <- 1:length(x)
for (i in 1:reps)
{
  sortvector <- sample(sortvector, replace = F)
  xtemp <- x[sortvector]
  M_temp <- sum(xtemp *y)
  results[i] <- M_temp
}
hist(results)
is_small <- sum(results 
                >M)
print(c("P of being so small is estimated as ", is_small/reps))

#Whole body sequences subset analysis
GTBody <-subset(GestureTokens, Type=='Body')
cor.test(GTBody$Size, GTBody$d, method = 'spearman', alternative = 'greater') #Correlation between t and n per each sequence
cor.test(GTBody$Size, GTBody$D, method = 'spearman') #Control correlation between T and n

#Is M significanlty small for mixed sequences?
reps <- 100000
results <- rep(0, reps)
x <- c(GTBody$Size)
y <- c(GTBody$d)
M <- sum(x*y)
print (c("real M is", M))
sortvector <- 1:length(x)
for (i in 1:reps)
{
  sortvector <- sample(sortvector, replace = F)
  xtemp <- x[sortvector]
  M_temp <- sum(xtemp *y)
  results[i] <- M_temp
}
hist(results)
is_small <- sum(results 
                >M)
print(c("P of being so small is estimated as ", is_small/reps))


#GLMM analysis ---- 

#load packages 
library(lme4)
library(Matrix)
library(MuMIn)
library(car)
library(carData)
library(multcomp)

#Load data
GLMMData <-read.csv(file.choose(), header=T)
GLMMData$logduration<-log(GLMMData$Duration) #transform duration in log


#Model 1 
Model1 <- lmer(logduration ~ Fsample + Category + Fsample*Category+(1|Signaller), 
                data=GLMMData)
summary(Model1)
confint(Model1)


ModelRankingAIC <-dredge(modelx, rank = 'AIC')
ModelRankingBIC <-dredge(modelx, rank = 'BIC')

#posthoc
summary(glht(GestureTypesModel, mcp(Context="Tukey")))


#No object shake Model 1 
GLMMNoOSData <- subset(GLMMData, Gesture != 'Object shake')
y=count(GLMMNoOSData, Gesture)
GLMMNoOSData<-left_join(GLMMNoOSData, y, by='Gesture')
GLMMNoOSData$Fsample1b<-(GLMMNoOSData$n/295)



Model1NOOS <- lmer(logduration ~ Fsample1b + Category + Fsample1b*Category+(1|Signaller), 
                           data=GLMMNoOSData)
summary(Model1NOOS)
confint(Model1NOOS)

Model1NOOSAIC <-dredge(Model1NOOS, rank = 'AIC')
Model1NOOSBIC <- dredge(Model1NOOS, rank='BIC')

#Menzerath's GLMM 
GestureTokens$logduration<-log(GestureTokens$d)

Model2 <- lmer(logduration ~ Type + Size + Type*Size+(1|Signaller), 
                           data=GestureTokens)
summary(Model2)
confint(Model2)

Model2AIC <-dredge(Model2, rank = 'AIC')
Model2BIC <- dredge(Model2, rank='BIC')

#post hoc
summary(glht(Model2, mcp(Type="Tukey")))

